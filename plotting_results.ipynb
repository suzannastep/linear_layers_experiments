{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "17b21cba",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#imports\" data-toc-modified-id=\"imports-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>imports</a></span></li><li><span><a href=\"#load-data\" data-toc-modified-id=\"load-data-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>load data</a></span><ul class=\"toc-item\"><li><span><a href=\"#read-in-the-files\" data-toc-modified-id=\"read-in-the-files-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>read in the files</a></span><ul class=\"toc-item\"><li><span><a href=\"#data-from-linear-and-relu-activations\" data-toc-modified-id=\"data-from-linear-and-relu-activations-2.1.1\"><span class=\"toc-item-num\">2.1.1&nbsp;&nbsp;</span>data from linear and relu activations</a></span></li></ul></li><li><span><a href=\"#create-pandas-table\" data-toc-modified-id=\"create-pandas-table-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>create pandas table</a></span></li></ul></li><li><span><a href=\"#filter-out-bad-training-losses\" data-toc-modified-id=\"filter-out-bad-training-losses-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>filter out bad training losses</a></span></li><li><span><a href=\"#determine-the-lambda-parameter-that-gets-the-best-test-MSE-for-each-(r,n,L)\" data-toc-modified-id=\"determine-the-lambda-parameter-that-gets-the-best-test-MSE-for-each-(r,n,L)-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>determine the lambda parameter that gets the best test MSE for each (r,n,L)</a></span></li><li><span><a href=\"#Generalization-MSE\" data-toc-modified-id=\"Generalization-MSE-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Generalization MSE</a></span><ul class=\"toc-item\"><li><span><a href=\"#generate-data\" data-toc-modified-id=\"generate-data-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;</span>generate data</a></span></li><li><span><a href=\"#compute-MSE\" data-toc-modified-id=\"compute-MSE-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;</span>compute MSE</a></span></li></ul></li><li><span><a href=\"#Out-of-Distribution-MSE\" data-toc-modified-id=\"Out-of-Distribution-MSE-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Out of Distribution MSE</a></span><ul class=\"toc-item\"><li><span><a href=\"#generate-data\" data-toc-modified-id=\"generate-data-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>generate data</a></span></li><li><span><a href=\"#compute-MSE\" data-toc-modified-id=\"compute-MSE-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>compute MSE</a></span></li></ul></li><li><span><a href=\"#Active-Subspace\" data-toc-modified-id=\"Active-Subspace-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Active Subspace</a></span><ul class=\"toc-item\"><li><span><a href=\"#evaluate-gradients-and-compute-singular-values-and-active-subspaces\" data-toc-modified-id=\"evaluate-gradients-and-compute-singular-values-and-active-subspaces-7.1\"><span class=\"toc-item-num\">7.1&nbsp;&nbsp;</span>evaluate gradients and compute singular values and active subspaces</a></span></li><li><span><a href=\"#plot-of-singular-values\" data-toc-modified-id=\"plot-of-singular-values-7.2\"><span class=\"toc-item-num\">7.2&nbsp;&nbsp;</span>plot of singular values</a></span></li></ul></li><li><span><a href=\"#determine-the-L-parameter-that-gets-the-best-test-MSE-for-each-(r,n)\" data-toc-modified-id=\"determine-the-L-parameter-that-gets-the-best-test-MSE-for-each-(r,n)-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>determine the L parameter that gets the best test MSE for each (r,n)</a></span></li><li><span><a href=\"#Plots-of-L-vs-Test-error-and-n-vs-Generalization-metrics-with/without-linear-layers\" data-toc-modified-id=\"Plots-of-L-vs-Test-error-and-n-vs-Generalization-metrics-with/without-linear-layers-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Plots of L vs Test error and n vs Generalization metrics with/without linear layers</a></span></li><li><span><a href=\"#Final-Table\" data-toc-modified-id=\"Final-Table-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Final Table</a></span></li><li><span><a href=\"#Training-Time-Plots\" data-toc-modified-id=\"Training-Time-Plots-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Training Time Plots</a></span><ul class=\"toc-item\"><li><span><a href=\"#Train-MSE-v-Epoch\" data-toc-modified-id=\"Train-MSE-v-Epoch-11.1\"><span class=\"toc-item-num\">11.1&nbsp;&nbsp;</span>Train MSE v Epoch</a></span></li><li><span><a href=\"#Weight-Decay-v-Epoch\" data-toc-modified-id=\"Weight-Decay-v-Epoch-11.2\"><span class=\"toc-item-num\">11.2&nbsp;&nbsp;</span>Weight Decay v Epoch</a></span></li><li><span><a href=\"#learning-rates\" data-toc-modified-id=\"learning-rates-11.3\"><span class=\"toc-item-num\">11.3&nbsp;&nbsp;</span>learning rates</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bF8A36cglU4",
   "metadata": {
    "id": "4bF8A36cglU4"
   },
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2cca449a",
   "metadata": {
    "executionInfo": {
     "elapsed": 1038,
     "status": "ok",
     "timestamp": 1701128286405,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 360
    },
    "id": "2cca449a"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.stats import ortho_group\n",
    "from scipy.stats import linregress\n",
    "from scipy import linalg as la\n",
    "from torch import nn\n",
    "import torch\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21725609",
   "metadata": {
    "id": "21725609"
   },
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aHdpcWWgi3RZ",
   "metadata": {
    "id": "aHdpcWWgi3RZ"
   },
   "source": [
    "## read in the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "s2Q_uTMFlmlR",
   "metadata": {
    "executionInfo": {
     "elapsed": 23,
     "status": "ok",
     "timestamp": 1701128289117,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 360
    },
    "id": "s2Q_uTMFlmlR"
   },
   "outputs": [],
   "source": [
    "rnvals = [(1,64),(1,128),(1,256),(1,512),(1,1024),(1,2048),\n",
    "          (2,64),(2,128),(2,256),(2,512),(2,1024),(2,2048)]\n",
    "Ls = [2,3,4,5,6,7,8,9]\n",
    "wds = [1e-3,1e-4,1e-5]\n",
    "epochs = 60100\n",
    "job_name = \"GPUmanylayers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "KW9hIU5glFu2",
   "metadata": {
    "id": "KW9hIU5glFu2"
   },
   "source": [
    "### data from linear and relu activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d588a3c2",
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1701128289117,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 360
    },
    "id": "d588a3c2",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "testMSEs = {}\n",
    "trainMSEs = {}\n",
    "weightdecays = {}\n",
    "learningrates = {}\n",
    "files_found_list = []\n",
    "for r,n in rnvals:\n",
    "    for L in Ls:\n",
    "        for wd in wds:\n",
    "            paramname = job_name+f\"/N{n}_L{L}_r{r}_wd{wd}_epochs{epochs}\"\n",
    "            if os.path.exists(paramname+\"testMSE.npy\"):\n",
    "                testMSEs[r,n,L,wd] = np.load(paramname+\"testMSE.npy\",allow_pickle=True).item()\n",
    "                trainMSEs[r,n,L,wd] = np.load(paramname+\"trainMSEs.npy\",allow_pickle=True)\n",
    "                weightdecays[r,n,L,wd] = np.load(paramname+\"weightdecays.npy\",allow_pickle=True)\n",
    "                learningrates[r,n,L,wd] = np.load(paramname+\"learningrates.npy\",allow_pickle=True)\n",
    "                files_found_list.append((r,n,L,wd))\n",
    "            else:\n",
    "                print(f\"{paramname+'testMSE.npy'} not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9ca93e4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 64, 2, 0.001),\n",
       " (1, 64, 2, 0.0001),\n",
       " (1, 64, 2, 1e-05),\n",
       " (1, 64, 3, 0.001),\n",
       " (1, 64, 3, 0.0001),\n",
       " (1, 64, 3, 1e-05),\n",
       " (1, 64, 4, 0.001),\n",
       " (1, 64, 4, 0.0001),\n",
       " (1, 64, 4, 1e-05),\n",
       " (1, 64, 5, 0.001),\n",
       " (1, 64, 5, 0.0001),\n",
       " (1, 64, 5, 1e-05),\n",
       " (1, 64, 6, 0.001),\n",
       " (1, 64, 6, 0.0001),\n",
       " (1, 64, 6, 1e-05),\n",
       " (1, 64, 7, 0.001),\n",
       " (1, 64, 7, 0.0001),\n",
       " (1, 64, 7, 1e-05),\n",
       " (1, 64, 8, 0.001),\n",
       " (1, 64, 8, 0.0001),\n",
       " (1, 64, 8, 1e-05),\n",
       " (1, 64, 9, 0.001),\n",
       " (1, 64, 9, 0.0001),\n",
       " (1, 64, 9, 1e-05),\n",
       " (1, 128, 2, 0.001),\n",
       " (1, 128, 2, 0.0001),\n",
       " (1, 128, 2, 1e-05),\n",
       " (1, 128, 3, 0.001),\n",
       " (1, 128, 3, 0.0001),\n",
       " (1, 128, 3, 1e-05),\n",
       " (1, 128, 4, 0.001),\n",
       " (1, 128, 4, 0.0001),\n",
       " (1, 128, 4, 1e-05),\n",
       " (1, 128, 5, 0.001),\n",
       " (1, 128, 5, 0.0001),\n",
       " (1, 128, 5, 1e-05),\n",
       " (1, 128, 6, 0.001),\n",
       " (1, 128, 6, 0.0001),\n",
       " (1, 128, 6, 1e-05),\n",
       " (1, 128, 7, 0.001),\n",
       " (1, 128, 7, 0.0001),\n",
       " (1, 128, 7, 1e-05),\n",
       " (1, 128, 8, 0.001),\n",
       " (1, 128, 8, 0.0001),\n",
       " (1, 128, 8, 1e-05),\n",
       " (1, 128, 9, 0.001),\n",
       " (1, 128, 9, 0.0001),\n",
       " (1, 128, 9, 1e-05),\n",
       " (1, 256, 2, 0.001),\n",
       " (1, 256, 2, 0.0001),\n",
       " (1, 256, 2, 1e-05),\n",
       " (1, 256, 3, 0.001),\n",
       " (1, 256, 3, 0.0001),\n",
       " (1, 256, 3, 1e-05),\n",
       " (1, 256, 4, 0.001),\n",
       " (1, 256, 4, 0.0001),\n",
       " (1, 256, 4, 1e-05),\n",
       " (1, 256, 5, 0.001),\n",
       " (1, 256, 5, 0.0001),\n",
       " (1, 256, 5, 1e-05),\n",
       " (1, 256, 6, 0.001),\n",
       " (1, 256, 6, 0.0001),\n",
       " (1, 256, 6, 1e-05),\n",
       " (1, 256, 7, 0.001),\n",
       " (1, 256, 7, 0.0001),\n",
       " (1, 256, 7, 1e-05),\n",
       " (1, 256, 8, 0.001),\n",
       " (1, 256, 8, 0.0001),\n",
       " (1, 256, 8, 1e-05),\n",
       " (1, 256, 9, 0.001),\n",
       " (1, 256, 9, 0.0001),\n",
       " (1, 256, 9, 1e-05),\n",
       " (1, 512, 2, 0.001),\n",
       " (1, 512, 2, 0.0001),\n",
       " (1, 512, 2, 1e-05),\n",
       " (1, 512, 3, 0.001),\n",
       " (1, 512, 3, 0.0001),\n",
       " (1, 512, 3, 1e-05),\n",
       " (1, 512, 4, 0.001),\n",
       " (1, 512, 4, 0.0001),\n",
       " (1, 512, 4, 1e-05),\n",
       " (1, 512, 5, 0.001),\n",
       " (1, 512, 5, 0.0001),\n",
       " (1, 512, 5, 1e-05),\n",
       " (1, 512, 6, 0.001),\n",
       " (1, 512, 6, 0.0001),\n",
       " (1, 512, 6, 1e-05),\n",
       " (1, 512, 7, 0.001),\n",
       " (1, 512, 7, 0.0001),\n",
       " (1, 512, 7, 1e-05),\n",
       " (1, 512, 8, 0.001),\n",
       " (1, 512, 8, 0.0001),\n",
       " (1, 512, 8, 1e-05),\n",
       " (1, 512, 9, 0.001),\n",
       " (1, 512, 9, 0.0001),\n",
       " (1, 512, 9, 1e-05),\n",
       " (1, 1024, 2, 0.001),\n",
       " (1, 1024, 2, 0.0001),\n",
       " (1, 1024, 2, 1e-05),\n",
       " (1, 1024, 3, 0.001),\n",
       " (1, 1024, 3, 0.0001),\n",
       " (1, 1024, 3, 1e-05),\n",
       " (1, 1024, 4, 0.001),\n",
       " (1, 1024, 4, 0.0001),\n",
       " (1, 1024, 4, 1e-05),\n",
       " (1, 1024, 5, 0.001),\n",
       " (1, 1024, 5, 0.0001),\n",
       " (1, 1024, 5, 1e-05),\n",
       " (1, 1024, 6, 0.001),\n",
       " (1, 1024, 6, 0.0001),\n",
       " (1, 1024, 6, 1e-05),\n",
       " (1, 1024, 7, 0.001),\n",
       " (1, 1024, 7, 0.0001),\n",
       " (1, 1024, 7, 1e-05),\n",
       " (1, 1024, 8, 0.001),\n",
       " (1, 1024, 8, 0.0001),\n",
       " (1, 1024, 8, 1e-05),\n",
       " (1, 1024, 9, 0.001),\n",
       " (1, 1024, 9, 0.0001),\n",
       " (1, 1024, 9, 1e-05),\n",
       " (1, 2048, 2, 0.001),\n",
       " (1, 2048, 2, 0.0001),\n",
       " (1, 2048, 2, 1e-05),\n",
       " (1, 2048, 3, 0.001),\n",
       " (1, 2048, 3, 0.0001),\n",
       " (1, 2048, 3, 1e-05),\n",
       " (1, 2048, 4, 0.001),\n",
       " (1, 2048, 4, 0.0001),\n",
       " (1, 2048, 4, 1e-05),\n",
       " (1, 2048, 5, 0.001),\n",
       " (1, 2048, 5, 0.0001),\n",
       " (1, 2048, 5, 1e-05),\n",
       " (1, 2048, 6, 0.001),\n",
       " (1, 2048, 6, 0.0001),\n",
       " (1, 2048, 6, 1e-05),\n",
       " (1, 2048, 7, 0.001),\n",
       " (1, 2048, 7, 0.0001),\n",
       " (1, 2048, 7, 1e-05),\n",
       " (1, 2048, 8, 0.001),\n",
       " (1, 2048, 8, 0.0001),\n",
       " (1, 2048, 8, 1e-05),\n",
       " (1, 2048, 9, 0.001),\n",
       " (1, 2048, 9, 0.0001),\n",
       " (1, 2048, 9, 1e-05),\n",
       " (2, 64, 2, 0.001),\n",
       " (2, 64, 2, 0.0001),\n",
       " (2, 64, 2, 1e-05),\n",
       " (2, 64, 3, 0.001),\n",
       " (2, 64, 3, 0.0001),\n",
       " (2, 64, 3, 1e-05),\n",
       " (2, 64, 4, 0.001),\n",
       " (2, 64, 4, 0.0001),\n",
       " (2, 64, 4, 1e-05),\n",
       " (2, 64, 5, 0.001),\n",
       " (2, 64, 5, 0.0001),\n",
       " (2, 64, 5, 1e-05),\n",
       " (2, 64, 6, 0.001),\n",
       " (2, 64, 6, 0.0001),\n",
       " (2, 64, 6, 1e-05),\n",
       " (2, 64, 7, 0.001),\n",
       " (2, 64, 7, 0.0001),\n",
       " (2, 64, 7, 1e-05),\n",
       " (2, 64, 8, 0.001),\n",
       " (2, 64, 8, 0.0001),\n",
       " (2, 64, 8, 1e-05),\n",
       " (2, 64, 9, 0.001),\n",
       " (2, 64, 9, 0.0001),\n",
       " (2, 64, 9, 1e-05),\n",
       " (2, 128, 2, 0.001),\n",
       " (2, 128, 2, 0.0001),\n",
       " (2, 128, 2, 1e-05),\n",
       " (2, 128, 3, 0.001),\n",
       " (2, 128, 3, 0.0001),\n",
       " (2, 128, 3, 1e-05),\n",
       " (2, 128, 4, 0.001),\n",
       " (2, 128, 4, 0.0001),\n",
       " (2, 128, 4, 1e-05),\n",
       " (2, 128, 5, 0.001),\n",
       " (2, 128, 5, 0.0001),\n",
       " (2, 128, 5, 1e-05),\n",
       " (2, 128, 6, 0.001),\n",
       " (2, 128, 6, 0.0001),\n",
       " (2, 128, 6, 1e-05),\n",
       " (2, 128, 7, 0.001),\n",
       " (2, 128, 7, 0.0001),\n",
       " (2, 128, 7, 1e-05),\n",
       " (2, 128, 8, 0.001),\n",
       " (2, 128, 8, 0.0001),\n",
       " (2, 128, 8, 1e-05),\n",
       " (2, 128, 9, 0.001),\n",
       " (2, 128, 9, 0.0001),\n",
       " (2, 128, 9, 1e-05),\n",
       " (2, 256, 2, 0.001),\n",
       " (2, 256, 2, 0.0001),\n",
       " (2, 256, 2, 1e-05),\n",
       " (2, 256, 3, 0.001),\n",
       " (2, 256, 3, 0.0001),\n",
       " (2, 256, 3, 1e-05),\n",
       " (2, 256, 4, 0.001),\n",
       " (2, 256, 4, 0.0001),\n",
       " (2, 256, 4, 1e-05),\n",
       " (2, 256, 5, 0.001),\n",
       " (2, 256, 5, 0.0001),\n",
       " (2, 256, 5, 1e-05),\n",
       " (2, 256, 6, 0.001),\n",
       " (2, 256, 6, 0.0001),\n",
       " (2, 256, 6, 1e-05),\n",
       " (2, 256, 7, 0.001),\n",
       " (2, 256, 7, 0.0001),\n",
       " (2, 256, 7, 1e-05),\n",
       " (2, 256, 8, 0.001),\n",
       " (2, 256, 8, 0.0001),\n",
       " (2, 256, 8, 1e-05),\n",
       " (2, 256, 9, 0.001),\n",
       " (2, 256, 9, 0.0001),\n",
       " (2, 256, 9, 1e-05),\n",
       " (2, 512, 2, 0.001),\n",
       " (2, 512, 2, 0.0001),\n",
       " (2, 512, 2, 1e-05),\n",
       " (2, 512, 3, 0.001),\n",
       " (2, 512, 3, 0.0001),\n",
       " (2, 512, 3, 1e-05),\n",
       " (2, 512, 4, 0.001),\n",
       " (2, 512, 4, 0.0001),\n",
       " (2, 512, 4, 1e-05),\n",
       " (2, 512, 5, 0.001),\n",
       " (2, 512, 5, 0.0001),\n",
       " (2, 512, 5, 1e-05),\n",
       " (2, 512, 6, 0.001),\n",
       " (2, 512, 6, 0.0001),\n",
       " (2, 512, 6, 1e-05),\n",
       " (2, 512, 7, 0.001),\n",
       " (2, 512, 7, 0.0001),\n",
       " (2, 512, 7, 1e-05),\n",
       " (2, 512, 8, 0.001),\n",
       " (2, 512, 8, 0.0001),\n",
       " (2, 512, 8, 1e-05),\n",
       " (2, 512, 9, 0.001),\n",
       " (2, 512, 9, 0.0001),\n",
       " (2, 512, 9, 1e-05),\n",
       " (2, 1024, 2, 0.001),\n",
       " (2, 1024, 2, 0.0001),\n",
       " (2, 1024, 2, 1e-05),\n",
       " (2, 1024, 3, 0.001),\n",
       " (2, 1024, 3, 0.0001),\n",
       " (2, 1024, 3, 1e-05),\n",
       " (2, 1024, 4, 0.001),\n",
       " (2, 1024, 4, 0.0001),\n",
       " (2, 1024, 4, 1e-05),\n",
       " (2, 1024, 5, 0.001),\n",
       " (2, 1024, 5, 0.0001),\n",
       " (2, 1024, 5, 1e-05),\n",
       " (2, 1024, 6, 0.001),\n",
       " (2, 1024, 6, 0.0001),\n",
       " (2, 1024, 6, 1e-05),\n",
       " (2, 1024, 7, 0.001),\n",
       " (2, 1024, 7, 0.0001),\n",
       " (2, 1024, 7, 1e-05),\n",
       " (2, 1024, 8, 0.001),\n",
       " (2, 1024, 8, 0.0001),\n",
       " (2, 1024, 8, 1e-05),\n",
       " (2, 1024, 9, 0.001),\n",
       " (2, 1024, 9, 0.0001),\n",
       " (2, 1024, 9, 1e-05),\n",
       " (2, 2048, 2, 0.001),\n",
       " (2, 2048, 2, 0.0001),\n",
       " (2, 2048, 2, 1e-05),\n",
       " (2, 2048, 3, 0.001),\n",
       " (2, 2048, 3, 0.0001),\n",
       " (2, 2048, 3, 1e-05),\n",
       " (2, 2048, 4, 0.001),\n",
       " (2, 2048, 4, 0.0001),\n",
       " (2, 2048, 4, 1e-05),\n",
       " (2, 2048, 5, 0.001),\n",
       " (2, 2048, 5, 0.0001),\n",
       " (2, 2048, 5, 1e-05),\n",
       " (2, 2048, 6, 0.001),\n",
       " (2, 2048, 6, 0.0001),\n",
       " (2, 2048, 6, 1e-05),\n",
       " (2, 2048, 7, 0.001),\n",
       " (2, 2048, 7, 0.0001),\n",
       " (2, 2048, 7, 1e-05),\n",
       " (2, 2048, 8, 0.001),\n",
       " (2, 2048, 8, 0.0001),\n",
       " (2, 2048, 8, 1e-05),\n",
       " (2, 2048, 9, 0.001),\n",
       " (2, 2048, 9, 0.0001),\n",
       " (2, 2048, 9, 1e-05)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_found_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "g92mE6Ljkoq9",
   "metadata": {
    "executionInfo": {
     "elapsed": 22,
     "status": "ok",
     "timestamp": 1701128289117,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 360
    },
    "id": "g92mE6Ljkoq9"
   },
   "outputs": [],
   "source": [
    "def Llayers(L,d=20,width=1000):\n",
    "    #construct L-1 linear layers; bias term only on last linear layer\n",
    "    if L < 2:\n",
    "        raise ValueError(\"L must be at least 2\")\n",
    "    if L == 2:\n",
    "        linear_layers = [nn.Linear(d,width,bias=True)]\n",
    "    if L > 2:\n",
    "        linear_layers = [nn.Linear(d,width,bias=False)]\n",
    "        for l in range(L-3):\n",
    "            linear_layers.append(nn.Linear(width,width,bias=False))\n",
    "        linear_layers.append(nn.Linear(width,width,bias=True))\n",
    "\n",
    "    relu = nn.ReLU()\n",
    "\n",
    "    last_layer = nn.Linear(width,1)\n",
    "\n",
    "    layers = linear_layers + [relu,last_layer]\n",
    "\n",
    "    return nn.Sequential(*layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "jl4Oh8Vp4QIb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 21,
     "status": "ok",
     "timestamp": 1701128289117,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 360
    },
    "id": "jl4Oh8Vp4QIb",
    "outputId": "8514097d-0db9-4bcd-baf4-42b4faad166a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda', index=0)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4G22AjiIkYNE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3672,
     "status": "ok",
     "timestamp": 1701128292778,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 360
    },
    "id": "4G22AjiIkYNE",
    "outputId": "4147ad49-f1a8-410f-c9bb-6822320eed52",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "files_found_list = []\n",
    "models = {}\n",
    "for r,n in rnvals:\n",
    "    for L in Ls:\n",
    "        for wd in wds:\n",
    "            paramname = job_name+f\"/N{n}_L{L}_r{r}_wd{wd}_epochs60100\"#f\"r{r}_N{n}\"\n",
    "            if os.path.exists(paramname+\"model.pt\"):\n",
    "                models[r,n,L,wd] = Llayers(L,width=1000)\n",
    "                models[r,n,L,wd].to(device)\n",
    "                if torch.cuda.is_available():\n",
    "                    models[r,n,L,wd].load_state_dict(torch.load(paramname+\"model.pt\"))\n",
    "                else:\n",
    "                    models[r,n,L,wd].load_state_dict(torch.load(paramname+\"model.pt\"),map_location=torch.device('cpu'))\n",
    "                models[r,n,L,wd].eval()\n",
    "                files_found_list.append((r,n,L,wd))\n",
    "            else:\n",
    "                print(paramname+\"model.pt\",\"not found\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "101bd89c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 64, 2, 0.001),\n",
       " (1, 64, 2, 0.0001),\n",
       " (1, 64, 2, 1e-05),\n",
       " (1, 64, 3, 0.001),\n",
       " (1, 64, 3, 0.0001),\n",
       " (1, 64, 3, 1e-05),\n",
       " (1, 64, 4, 0.001),\n",
       " (1, 64, 4, 0.0001),\n",
       " (1, 64, 4, 1e-05),\n",
       " (1, 64, 5, 0.001),\n",
       " (1, 64, 5, 0.0001),\n",
       " (1, 64, 5, 1e-05),\n",
       " (1, 64, 6, 0.001),\n",
       " (1, 64, 6, 0.0001),\n",
       " (1, 64, 6, 1e-05),\n",
       " (1, 64, 7, 0.001),\n",
       " (1, 64, 7, 0.0001),\n",
       " (1, 64, 7, 1e-05),\n",
       " (1, 64, 8, 0.001),\n",
       " (1, 64, 8, 0.0001),\n",
       " (1, 64, 8, 1e-05),\n",
       " (1, 64, 9, 0.001),\n",
       " (1, 64, 9, 0.0001),\n",
       " (1, 64, 9, 1e-05),\n",
       " (1, 128, 2, 0.001),\n",
       " (1, 128, 2, 0.0001),\n",
       " (1, 128, 2, 1e-05),\n",
       " (1, 128, 3, 0.001),\n",
       " (1, 128, 3, 0.0001),\n",
       " (1, 128, 3, 1e-05),\n",
       " (1, 128, 4, 0.001),\n",
       " (1, 128, 4, 0.0001),\n",
       " (1, 128, 4, 1e-05),\n",
       " (1, 128, 5, 0.001),\n",
       " (1, 128, 5, 0.0001),\n",
       " (1, 128, 5, 1e-05),\n",
       " (1, 128, 6, 0.001),\n",
       " (1, 128, 6, 0.0001),\n",
       " (1, 128, 6, 1e-05),\n",
       " (1, 128, 7, 0.001),\n",
       " (1, 128, 7, 0.0001),\n",
       " (1, 128, 7, 1e-05),\n",
       " (1, 128, 8, 0.001),\n",
       " (1, 128, 8, 0.0001),\n",
       " (1, 128, 8, 1e-05),\n",
       " (1, 128, 9, 0.001),\n",
       " (1, 128, 9, 0.0001),\n",
       " (1, 128, 9, 1e-05),\n",
       " (1, 256, 2, 0.001),\n",
       " (1, 256, 2, 0.0001),\n",
       " (1, 256, 2, 1e-05),\n",
       " (1, 256, 3, 0.001),\n",
       " (1, 256, 3, 0.0001),\n",
       " (1, 256, 3, 1e-05),\n",
       " (1, 256, 4, 0.001),\n",
       " (1, 256, 4, 0.0001),\n",
       " (1, 256, 4, 1e-05),\n",
       " (1, 256, 5, 0.001),\n",
       " (1, 256, 5, 0.0001),\n",
       " (1, 256, 5, 1e-05),\n",
       " (1, 256, 6, 0.001),\n",
       " (1, 256, 6, 0.0001),\n",
       " (1, 256, 6, 1e-05),\n",
       " (1, 256, 7, 0.001),\n",
       " (1, 256, 7, 0.0001),\n",
       " (1, 256, 7, 1e-05),\n",
       " (1, 256, 8, 0.001),\n",
       " (1, 256, 8, 0.0001),\n",
       " (1, 256, 8, 1e-05),\n",
       " (1, 256, 9, 0.001),\n",
       " (1, 256, 9, 0.0001),\n",
       " (1, 256, 9, 1e-05),\n",
       " (1, 512, 2, 0.001),\n",
       " (1, 512, 2, 0.0001),\n",
       " (1, 512, 2, 1e-05),\n",
       " (1, 512, 3, 0.001),\n",
       " (1, 512, 3, 0.0001),\n",
       " (1, 512, 3, 1e-05),\n",
       " (1, 512, 4, 0.001),\n",
       " (1, 512, 4, 0.0001),\n",
       " (1, 512, 4, 1e-05),\n",
       " (1, 512, 5, 0.001),\n",
       " (1, 512, 5, 0.0001),\n",
       " (1, 512, 5, 1e-05),\n",
       " (1, 512, 6, 0.001),\n",
       " (1, 512, 6, 0.0001),\n",
       " (1, 512, 6, 1e-05),\n",
       " (1, 512, 7, 0.001),\n",
       " (1, 512, 7, 0.0001),\n",
       " (1, 512, 7, 1e-05),\n",
       " (1, 512, 8, 0.001),\n",
       " (1, 512, 8, 0.0001),\n",
       " (1, 512, 8, 1e-05),\n",
       " (1, 512, 9, 0.001),\n",
       " (1, 512, 9, 0.0001),\n",
       " (1, 512, 9, 1e-05),\n",
       " (1, 1024, 2, 0.001),\n",
       " (1, 1024, 2, 0.0001),\n",
       " (1, 1024, 2, 1e-05),\n",
       " (1, 1024, 3, 0.001),\n",
       " (1, 1024, 3, 0.0001),\n",
       " (1, 1024, 3, 1e-05),\n",
       " (1, 1024, 4, 0.001),\n",
       " (1, 1024, 4, 0.0001),\n",
       " (1, 1024, 4, 1e-05),\n",
       " (1, 1024, 5, 0.001),\n",
       " (1, 1024, 5, 0.0001),\n",
       " (1, 1024, 5, 1e-05),\n",
       " (1, 1024, 6, 0.001),\n",
       " (1, 1024, 6, 0.0001),\n",
       " (1, 1024, 6, 1e-05),\n",
       " (1, 1024, 7, 0.001),\n",
       " (1, 1024, 7, 0.0001),\n",
       " (1, 1024, 7, 1e-05),\n",
       " (1, 1024, 8, 0.001),\n",
       " (1, 1024, 8, 0.0001),\n",
       " (1, 1024, 8, 1e-05),\n",
       " (1, 1024, 9, 0.001),\n",
       " (1, 1024, 9, 0.0001),\n",
       " (1, 1024, 9, 1e-05),\n",
       " (1, 2048, 2, 0.001),\n",
       " (1, 2048, 2, 0.0001),\n",
       " (1, 2048, 2, 1e-05),\n",
       " (1, 2048, 3, 0.001),\n",
       " (1, 2048, 3, 0.0001),\n",
       " (1, 2048, 3, 1e-05),\n",
       " (1, 2048, 4, 0.001),\n",
       " (1, 2048, 4, 0.0001),\n",
       " (1, 2048, 4, 1e-05),\n",
       " (1, 2048, 5, 0.001),\n",
       " (1, 2048, 5, 0.0001),\n",
       " (1, 2048, 5, 1e-05),\n",
       " (1, 2048, 6, 0.001),\n",
       " (1, 2048, 6, 0.0001),\n",
       " (1, 2048, 6, 1e-05),\n",
       " (1, 2048, 7, 0.001),\n",
       " (1, 2048, 7, 0.0001),\n",
       " (1, 2048, 7, 1e-05),\n",
       " (1, 2048, 8, 0.001),\n",
       " (1, 2048, 8, 0.0001),\n",
       " (1, 2048, 8, 1e-05),\n",
       " (1, 2048, 9, 0.001),\n",
       " (1, 2048, 9, 0.0001),\n",
       " (1, 2048, 9, 1e-05),\n",
       " (2, 64, 2, 0.001),\n",
       " (2, 64, 2, 0.0001),\n",
       " (2, 64, 2, 1e-05),\n",
       " (2, 64, 3, 0.001),\n",
       " (2, 64, 3, 0.0001),\n",
       " (2, 64, 3, 1e-05),\n",
       " (2, 64, 4, 0.001),\n",
       " (2, 64, 4, 0.0001),\n",
       " (2, 64, 4, 1e-05),\n",
       " (2, 64, 5, 0.001),\n",
       " (2, 64, 5, 0.0001),\n",
       " (2, 64, 5, 1e-05),\n",
       " (2, 64, 6, 0.001),\n",
       " (2, 64, 6, 0.0001),\n",
       " (2, 64, 6, 1e-05),\n",
       " (2, 64, 7, 0.001),\n",
       " (2, 64, 7, 0.0001),\n",
       " (2, 64, 7, 1e-05),\n",
       " (2, 64, 8, 0.001),\n",
       " (2, 64, 8, 0.0001),\n",
       " (2, 64, 8, 1e-05),\n",
       " (2, 64, 9, 0.001),\n",
       " (2, 64, 9, 0.0001),\n",
       " (2, 64, 9, 1e-05),\n",
       " (2, 128, 2, 0.001),\n",
       " (2, 128, 2, 0.0001),\n",
       " (2, 128, 2, 1e-05),\n",
       " (2, 128, 3, 0.001),\n",
       " (2, 128, 3, 0.0001),\n",
       " (2, 128, 3, 1e-05),\n",
       " (2, 128, 4, 0.001),\n",
       " (2, 128, 4, 0.0001),\n",
       " (2, 128, 4, 1e-05),\n",
       " (2, 128, 5, 0.001),\n",
       " (2, 128, 5, 0.0001),\n",
       " (2, 128, 5, 1e-05),\n",
       " (2, 128, 6, 0.001),\n",
       " (2, 128, 6, 0.0001),\n",
       " (2, 128, 6, 1e-05),\n",
       " (2, 128, 7, 0.001),\n",
       " (2, 128, 7, 0.0001),\n",
       " (2, 128, 7, 1e-05),\n",
       " (2, 128, 8, 0.001),\n",
       " (2, 128, 8, 0.0001),\n",
       " (2, 128, 8, 1e-05),\n",
       " (2, 128, 9, 0.001),\n",
       " (2, 128, 9, 0.0001),\n",
       " (2, 128, 9, 1e-05),\n",
       " (2, 256, 2, 0.001),\n",
       " (2, 256, 2, 0.0001),\n",
       " (2, 256, 2, 1e-05),\n",
       " (2, 256, 3, 0.001),\n",
       " (2, 256, 3, 0.0001),\n",
       " (2, 256, 3, 1e-05),\n",
       " (2, 256, 4, 0.001),\n",
       " (2, 256, 4, 0.0001),\n",
       " (2, 256, 4, 1e-05),\n",
       " (2, 256, 5, 0.001),\n",
       " (2, 256, 5, 0.0001),\n",
       " (2, 256, 5, 1e-05),\n",
       " (2, 256, 6, 0.001),\n",
       " (2, 256, 6, 0.0001),\n",
       " (2, 256, 6, 1e-05),\n",
       " (2, 256, 7, 0.001),\n",
       " (2, 256, 7, 0.0001),\n",
       " (2, 256, 7, 1e-05),\n",
       " (2, 256, 8, 0.001),\n",
       " (2, 256, 8, 0.0001),\n",
       " (2, 256, 8, 1e-05),\n",
       " (2, 256, 9, 0.001),\n",
       " (2, 256, 9, 0.0001),\n",
       " (2, 256, 9, 1e-05),\n",
       " (2, 512, 2, 0.001),\n",
       " (2, 512, 2, 0.0001),\n",
       " (2, 512, 2, 1e-05),\n",
       " (2, 512, 3, 0.001),\n",
       " (2, 512, 3, 0.0001),\n",
       " (2, 512, 3, 1e-05),\n",
       " (2, 512, 4, 0.001),\n",
       " (2, 512, 4, 0.0001),\n",
       " (2, 512, 4, 1e-05),\n",
       " (2, 512, 5, 0.001),\n",
       " (2, 512, 5, 0.0001),\n",
       " (2, 512, 5, 1e-05),\n",
       " (2, 512, 6, 0.001),\n",
       " (2, 512, 6, 0.0001),\n",
       " (2, 512, 6, 1e-05),\n",
       " (2, 512, 7, 0.001),\n",
       " (2, 512, 7, 0.0001),\n",
       " (2, 512, 7, 1e-05),\n",
       " (2, 512, 8, 0.001),\n",
       " (2, 512, 8, 0.0001),\n",
       " (2, 512, 8, 1e-05),\n",
       " (2, 512, 9, 0.001),\n",
       " (2, 512, 9, 0.0001),\n",
       " (2, 512, 9, 1e-05),\n",
       " (2, 1024, 2, 0.001),\n",
       " (2, 1024, 2, 0.0001),\n",
       " (2, 1024, 2, 1e-05),\n",
       " (2, 1024, 3, 0.001),\n",
       " (2, 1024, 3, 0.0001),\n",
       " (2, 1024, 3, 1e-05),\n",
       " (2, 1024, 4, 0.001),\n",
       " (2, 1024, 4, 0.0001),\n",
       " (2, 1024, 4, 1e-05),\n",
       " (2, 1024, 5, 0.001),\n",
       " (2, 1024, 5, 0.0001),\n",
       " (2, 1024, 5, 1e-05),\n",
       " (2, 1024, 6, 0.001),\n",
       " (2, 1024, 6, 0.0001),\n",
       " (2, 1024, 6, 1e-05),\n",
       " (2, 1024, 7, 0.001),\n",
       " (2, 1024, 7, 0.0001),\n",
       " (2, 1024, 7, 1e-05),\n",
       " (2, 1024, 8, 0.001),\n",
       " (2, 1024, 8, 0.0001),\n",
       " (2, 1024, 8, 1e-05),\n",
       " (2, 1024, 9, 0.001),\n",
       " (2, 1024, 9, 0.0001),\n",
       " (2, 1024, 9, 1e-05),\n",
       " (2, 2048, 2, 0.001),\n",
       " (2, 2048, 2, 0.0001),\n",
       " (2, 2048, 2, 1e-05),\n",
       " (2, 2048, 3, 0.001),\n",
       " (2, 2048, 3, 0.0001),\n",
       " (2, 2048, 3, 1e-05),\n",
       " (2, 2048, 4, 0.001),\n",
       " (2, 2048, 4, 0.0001),\n",
       " (2, 2048, 4, 1e-05),\n",
       " (2, 2048, 5, 0.001),\n",
       " (2, 2048, 5, 0.0001),\n",
       " (2, 2048, 5, 1e-05),\n",
       " (2, 2048, 6, 0.001),\n",
       " (2, 2048, 6, 0.0001),\n",
       " (2, 2048, 6, 1e-05),\n",
       " (2, 2048, 7, 0.001),\n",
       " (2, 2048, 7, 0.0001),\n",
       " (2, 2048, 7, 1e-05),\n",
       " (2, 2048, 8, 0.001),\n",
       " (2, 2048, 8, 0.0001),\n",
       " (2, 2048, 8, 1e-05),\n",
       " (2, 2048, 9, 0.001),\n",
       " (2, 2048, 9, 0.0001),\n",
       " (2, 2048, 9, 1e-05)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_found_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Wt9Aud_elI-7",
   "metadata": {
    "id": "Wt9Aud_elI-7"
   },
   "source": [
    "## create pandas table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8hubUl6NlIh3",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 30,
     "status": "ok",
     "timestamp": 1701128292779,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 360
    },
    "id": "8hubUl6NlIh3",
    "outputId": "008a8a90-61cb-40fb-e1fe-d5a2df77ddb8"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>n</th>\n",
       "      <th>L</th>\n",
       "      <th>lambda</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Weight Decay</th>\n",
       "      <th>Model</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Activations</th>\n",
       "      <th>Final Train MSE</th>\n",
       "      <th>Final Weight Decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[46.94083, 46.85972, 46.77882, 46.698128, 46.6...</td>\n",
       "      <td>[1340.811, 1340.6844, 1340.561, 1340.4401, 134...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.119706</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>3.649561e-06</td>\n",
       "      <td>228.721588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[46.94083, 46.859703, 46.7788, 46.698097, 46.6...</td>\n",
       "      <td>[1340.8812, 1340.8269, 1340.7769, 1340.7301, 1...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.176121</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>3.919119e-09</td>\n",
       "      <td>230.157959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[46.940826, 46.859707, 46.7788, 46.698097, 46....</td>\n",
       "      <td>[1340.8917, 1340.8499, 1340.8105, 1340.7739, 1...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.697939</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>2.046273e-12</td>\n",
       "      <td>249.742188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[46.71048, 46.291706, 45.88084, 45.47898, 45.0...</td>\n",
       "      <td>[3341.586, 3341.4255, 3341.3818, 3341.4531, 33...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.015205</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>1.265198e-04</td>\n",
       "      <td>151.614090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[46.710453, 46.291626, 45.88073, 45.478848, 45...</td>\n",
       "      <td>[3341.833, 3341.9233, 3342.1328, 3342.459, 334...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>1.132934e-06</td>\n",
       "      <td>178.268677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[46.562706, 39.381737, 17.358593, 10.517123, 9...</td>\n",
       "      <td>[23523.12, 23560.178, 23668.205, 23642.596, 23...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>1.692415e-05</td>\n",
       "      <td>521.803589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[46.5625, 39.316772, 17.49003, 10.495918, 9.45...</td>\n",
       "      <td>[23546.506, 23585.86, 23694.807, 23670.02, 236...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>1.435368e-05</td>\n",
       "      <td>720.301086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>285</th>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[48.673347, 27.75809, 15.627261, 14.277113, 11...</td>\n",
       "      <td>[29144.451, 29154.033, 29159.953, 29155.61, 29...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.000199</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>6.726003e-05</td>\n",
       "      <td>556.805176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>286</th>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[48.416122, 27.804901, 15.694317, 14.074917, 1...</td>\n",
       "      <td>[29420.867, 29445.838, 29472.56, 29491.002, 29...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>1.144927e-05</td>\n",
       "      <td>567.734436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[48.359787, 27.109566, 15.680702, 13.933253, 1...</td>\n",
       "      <td>[29459.785, 29487.56, 29514.674, 29537.557, 29...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>9.713471e-06</td>\n",
       "      <td>819.545837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>288 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     r     n  L   lambda                                      Learning Rate  \\\n",
       "0    1    64  2  0.00100  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "1    1    64  2  0.00010  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "2    1    64  2  0.00001  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "3    1    64  3  0.00100  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "4    1    64  3  0.00010  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "..  ..   ... ..      ...                                                ...   \n",
       "283  2  2048  8  0.00010  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "284  2  2048  8  0.00001  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "285  2  2048  9  0.00100  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "286  2  2048  9  0.00010  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "287  2  2048  9  0.00001  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "\n",
       "                                             Train MSE  \\\n",
       "0    [46.94083, 46.85972, 46.77882, 46.698128, 46.6...   \n",
       "1    [46.94083, 46.859703, 46.7788, 46.698097, 46.6...   \n",
       "2    [46.940826, 46.859707, 46.7788, 46.698097, 46....   \n",
       "3    [46.71048, 46.291706, 45.88084, 45.47898, 45.0...   \n",
       "4    [46.710453, 46.291626, 45.88073, 45.478848, 45...   \n",
       "..                                                 ...   \n",
       "283  [46.562706, 39.381737, 17.358593, 10.517123, 9...   \n",
       "284  [46.5625, 39.316772, 17.49003, 10.495918, 9.45...   \n",
       "285  [48.673347, 27.75809, 15.627261, 14.277113, 11...   \n",
       "286  [48.416122, 27.804901, 15.694317, 14.074917, 1...   \n",
       "287  [48.359787, 27.109566, 15.680702, 13.933253, 1...   \n",
       "\n",
       "                                          Weight Decay  \\\n",
       "0    [1340.811, 1340.6844, 1340.561, 1340.4401, 134...   \n",
       "1    [1340.8812, 1340.8269, 1340.7769, 1340.7301, 1...   \n",
       "2    [1340.8917, 1340.8499, 1340.8105, 1340.7739, 1...   \n",
       "3    [3341.586, 3341.4255, 3341.3818, 3341.4531, 33...   \n",
       "4    [3341.833, 3341.9233, 3342.1328, 3342.459, 334...   \n",
       "..                                                 ...   \n",
       "283  [23523.12, 23560.178, 23668.205, 23642.596, 23...   \n",
       "284  [23546.506, 23585.86, 23694.807, 23670.02, 236...   \n",
       "285  [29144.451, 29154.033, 29159.953, 29155.61, 29...   \n",
       "286  [29420.867, 29445.838, 29472.56, 29491.002, 29...   \n",
       "287  [29459.785, 29487.56, 29514.674, 29537.557, 29...   \n",
       "\n",
       "                                                 Model  Test MSE  \\\n",
       "0    [Linear(in_features=20, out_features=1000, bia...  0.119706   \n",
       "1    [Linear(in_features=20, out_features=1000, bia...  0.176121   \n",
       "2    [Linear(in_features=20, out_features=1000, bia...  0.697939   \n",
       "3    [Linear(in_features=20, out_features=1000, bia...  0.015205   \n",
       "4    [Linear(in_features=20, out_features=1000, bia...  0.012496   \n",
       "..                                                 ...       ...   \n",
       "283  [Linear(in_features=20, out_features=1000, bia...  0.000101   \n",
       "284  [Linear(in_features=20, out_features=1000, bia...  0.000095   \n",
       "285  [Linear(in_features=20, out_features=1000, bia...  0.000199   \n",
       "286  [Linear(in_features=20, out_features=1000, bia...  0.000102   \n",
       "287  [Linear(in_features=20, out_features=1000, bia...  0.000100   \n",
       "\n",
       "         Activations  Final Train MSE  Final Weight Decay  \n",
       "0    linear and relu     3.649561e-06          228.721588  \n",
       "1    linear and relu     3.919119e-09          230.157959  \n",
       "2    linear and relu     2.046273e-12          249.742188  \n",
       "3    linear and relu     1.265198e-04          151.614090  \n",
       "4    linear and relu     1.132934e-06          178.268677  \n",
       "..               ...              ...                 ...  \n",
       "283  linear and relu     1.692415e-05          521.803589  \n",
       "284  linear and relu     1.435368e-05          720.301086  \n",
       "285  linear and relu     6.726003e-05          556.805176  \n",
       "286  linear and relu     1.144927e-05          567.734436  \n",
       "287  linear and relu     9.713471e-06          819.545837  \n",
       "\n",
       "[288 rows x 12 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = {\n",
    "  \"r\"                 : [r                         for r,n,L,wd in files_found_list],# + [r                         for wd in wds for r,n in relu_rnvals],\n",
    "  \"n\"                 : [n                         for r,n,L,wd in files_found_list],# + [n                         for wd in wds for r,n in relu_rnvals],\n",
    "  \"L\"                 : [L                         for r,n,L,wd in files_found_list],# + [4                         for wd in wds for r,n in relu_rnvals],\n",
    "  \"lambda\"            : [wd                        for r,n,L,wd in files_found_list],# + [wd                        for wd in wds for r,n in relu_rnvals],\n",
    "  \"Learning Rate\"     : [learningrates[r,n,L,wd]   for r,n,L,wd in files_found_list],# + [RELUlearningrates[r,n][4][wd] for wd in wds for r,n in relu_rnvals],\n",
    "  \"Train MSE\"         : [trainMSEs[r,n,L,wd]       for r,n,L,wd in files_found_list],# + [RELUtrainMSEs[r,n][4][wd]     for wd in wds for r,n in relu_rnvals],\n",
    "  \"Weight Decay\"      : [weightdecays[r,n,L,wd]    for r,n,L,wd in files_found_list],# + [RELUweightdecays[r,n][4][wd]  for wd in wds for r,n in relu_rnvals],\n",
    "  \"Model\"             : [models[r,n,L,wd]          for r,n,L,wd in files_found_list],# + [RELUmodels[r,n,4,wd]          for wd in wds for r,n in relu_rnvals],\n",
    "  \"Test MSE\"          : [testMSEs[r,n,L,wd]        for r,n,L,wd in files_found_list],# + [RELUtestMSEs[r,n][4][wd].item()      for wd in wds for r,n in relu_rnvals],\n",
    "  \"Activations\"       : [\"linear and relu\"         for r,n,L,wd in files_found_list],# + [\"relu only\"         for wd in wds for r,n in relu_rnvals]\n",
    "}\n",
    "res = pd.DataFrame(res)\n",
    "res[\"Final Train MSE\"] = [r[-1] for r in res[\"Train MSE\"]]\n",
    "res[\"Final Weight Decay\"] = [r[-1] for r in res[\"Weight Decay\"]]\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b2d3b4",
   "metadata": {},
   "source": [
    "# filter out bad training losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "166e6a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "res[res[\"Final Train MSE\"] >= 1e-2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aX7gRNo_xet",
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1701128292779,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 360
    },
    "id": "4aX7gRNo_xet"
   },
   "outputs": [],
   "source": [
    "res = res[res[\"Final Train MSE\"] < 1e-2]\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QfTgwsYWt0JN",
   "metadata": {
    "id": "QfTgwsYWt0JN"
   },
   "source": [
    "#  determine the lambda parameter that gets the best test MSE for each (r,n,L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "RJvhVj2QsOzz",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1701128292779,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 360
    },
    "id": "RJvhVj2QsOzz",
    "outputId": "f5ab0e61-f93e-4d47-c809-af5ef4d06e06",
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>lambda</th>\n",
       "      <th>0.00001</th>\n",
       "      <th>0.00010</th>\n",
       "      <th>0.00100</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>r</th>\n",
       "      <th>n</th>\n",
       "      <th>L</th>\n",
       "      <th>Activations</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">1</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">64</th>\n",
       "      <th>2</th>\n",
       "      <th>linear and relu</th>\n",
       "      <td>0.697939</td>\n",
       "      <td>0.176121</td>\n",
       "      <td>0.119706</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <th>linear and relu</th>\n",
       "      <td>0.324526</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>0.015205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <th>linear and relu</th>\n",
       "      <td>0.055462</td>\n",
       "      <td>0.018579</td>\n",
       "      <td>0.000995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <th>linear and relu</th>\n",
       "      <td>0.067298</td>\n",
       "      <td>0.028189</td>\n",
       "      <td>0.000695</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>linear and relu</th>\n",
       "      <td>0.073758</td>\n",
       "      <td>0.033879</td>\n",
       "      <td>0.000725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">2</th>\n",
       "      <th rowspan=\"5\" valign=\"top\">2048</th>\n",
       "      <th>5</th>\n",
       "      <th>linear and relu</th>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000106</td>\n",
       "      <td>0.000411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <th>linear and relu</th>\n",
       "      <td>0.000092</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <th>linear and relu</th>\n",
       "      <td>0.000098</td>\n",
       "      <td>0.000099</td>\n",
       "      <td>0.000233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <th>linear and relu</th>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000101</td>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <th>linear and relu</th>\n",
       "      <td>0.000100</td>\n",
       "      <td>0.000102</td>\n",
       "      <td>0.000199</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "lambda                     0.00001   0.00010   0.00100\n",
       "r n    L Activations                                  \n",
       "1 64   2 linear and relu  0.697939  0.176121  0.119706\n",
       "       3 linear and relu  0.324526  0.012496  0.015205\n",
       "       4 linear and relu  0.055462  0.018579  0.000995\n",
       "       5 linear and relu  0.067298  0.028189  0.000695\n",
       "       6 linear and relu  0.073758  0.033879  0.000725\n",
       "...                            ...       ...       ...\n",
       "2 2048 5 linear and relu  0.000092  0.000106  0.000411\n",
       "       6 linear and relu  0.000092  0.000098  0.000284\n",
       "       7 linear and relu  0.000098  0.000099  0.000233\n",
       "       8 linear and relu  0.000095  0.000101  0.000199\n",
       "       9 linear and relu  0.000100  0.000102  0.000199\n",
       "\n",
       "[96 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testmse_vs_lambda = res.pivot_table(values=\"Test MSE\",index = (\"r\",\"n\",\"L\",\"Activations\"),columns=[\"lambda\"])\n",
    "testmse_vs_lambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "VAo89WtwHFHa",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1701128292779,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 360
    },
    "id": "VAo89WtwHFHa",
    "outputId": "8e14cccf-c936-4617-ee75-266196fa044a",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "r  n     L  Activations    \n",
       "1  64    2  linear and relu    0.00100\n",
       "         3  linear and relu    0.00010\n",
       "         4  linear and relu    0.00100\n",
       "         5  linear and relu    0.00100\n",
       "         6  linear and relu    0.00100\n",
       "                                ...   \n",
       "2  2048  5  linear and relu    0.00001\n",
       "         6  linear and relu    0.00001\n",
       "         7  linear and relu    0.00001\n",
       "         8  linear and relu    0.00001\n",
       "         9  linear and relu    0.00001\n",
       "Length: 96, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bestlambda = testmse_vs_lambda.idxmin(axis=1)\n",
    "bestlambda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "K4ItJEBcjtcZ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 960
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1701128292779,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 360
    },
    "id": "K4ItJEBcjtcZ",
    "outputId": "a6ab9ade-ea9d-4b83-b14b-29dd2811b57d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>r</th>\n",
       "      <th>n</th>\n",
       "      <th>L</th>\n",
       "      <th>lambda</th>\n",
       "      <th>Learning Rate</th>\n",
       "      <th>Train MSE</th>\n",
       "      <th>Weight Decay</th>\n",
       "      <th>Model</th>\n",
       "      <th>Test MSE</th>\n",
       "      <th>Activations</th>\n",
       "      <th>Final Train MSE</th>\n",
       "      <th>Final Weight Decay</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[46.94083, 46.85972, 46.77882, 46.698128, 46.6...</td>\n",
       "      <td>[1340.811, 1340.6844, 1340.561, 1340.4401, 134...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.119706</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>0.000004</td>\n",
       "      <td>228.721588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00010</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[46.710453, 46.291626, 45.88073, 45.478848, 45...</td>\n",
       "      <td>[3341.833, 3341.9233, 3342.1328, 3342.459, 334...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.012496</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>0.000001</td>\n",
       "      <td>178.268677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>4</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[46.590126, 46.100685, 45.620777, 45.14263, 44...</td>\n",
       "      <td>[6009.557, 6009.319, 6009.3955, 6009.7773, 601...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.000995</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>0.000058</td>\n",
       "      <td>147.673447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[46.45391, 46.070526, 45.691345, 45.296654, 44...</td>\n",
       "      <td>[9342.156, 9341.23, 9340.908, 9341.171, 9341.9...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.000695</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>151.917374</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1</td>\n",
       "      <td>64</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00100</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[46.611046, 46.307167, 45.982555, 45.605865, 4...</td>\n",
       "      <td>[13338.912, 13335.697, 13333.5625, 13332.438, ...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.000725</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>0.000082</td>\n",
       "      <td>166.722778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[79.03601, 14.673456, 7.1955748, 6.301117, 5.8...</td>\n",
       "      <td>[9526.033, 9935.584, 9980.475, 10001.476, 1001...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>597.575500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>278</th>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>6</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[48.78592, 11.064767, 8.407269, 7.039444, 6.65...</td>\n",
       "      <td>[13612.924, 13812.055, 13849.014, 13880.938, 1...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.000092</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>0.000008</td>\n",
       "      <td>581.571960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>281</th>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>7</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[37.673447, 11.727802, 8.1880665, 7.1784163, 6...</td>\n",
       "      <td>[18368.146, 18397.58, 18442.668, 18463.33, 184...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.000098</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>0.000011</td>\n",
       "      <td>625.433533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>8</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[46.5625, 39.316772, 17.49003, 10.495918, 9.45...</td>\n",
       "      <td>[23546.506, 23585.86, 23694.807, 23670.02, 236...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>0.000014</td>\n",
       "      <td>720.301086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>287</th>\n",
       "      <td>2</td>\n",
       "      <td>2048</td>\n",
       "      <td>9</td>\n",
       "      <td>0.00001</td>\n",
       "      <td>[1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...</td>\n",
       "      <td>[48.359787, 27.109566, 15.680702, 13.933253, 1...</td>\n",
       "      <td>[29459.785, 29487.56, 29514.674, 29537.557, 29...</td>\n",
       "      <td>[Linear(in_features=20, out_features=1000, bia...</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>linear and relu</td>\n",
       "      <td>0.000010</td>\n",
       "      <td>819.545837</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     r     n  L   lambda                                      Learning Rate  \\\n",
       "0    1    64  2  0.00100  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "4    1    64  3  0.00010  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "6    1    64  4  0.00100  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "9    1    64  5  0.00100  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "12   1    64  6  0.00100  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "..  ..   ... ..      ...                                                ...   \n",
       "275  2  2048  5  0.00001  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "278  2  2048  6  0.00001  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "281  2  2048  7  0.00001  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "284  2  2048  8  0.00001  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "287  2  2048  9  0.00001  [1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-04, 1e-...   \n",
       "\n",
       "                                             Train MSE  \\\n",
       "0    [46.94083, 46.85972, 46.77882, 46.698128, 46.6...   \n",
       "4    [46.710453, 46.291626, 45.88073, 45.478848, 45...   \n",
       "6    [46.590126, 46.100685, 45.620777, 45.14263, 44...   \n",
       "9    [46.45391, 46.070526, 45.691345, 45.296654, 44...   \n",
       "12   [46.611046, 46.307167, 45.982555, 45.605865, 4...   \n",
       "..                                                 ...   \n",
       "275  [79.03601, 14.673456, 7.1955748, 6.301117, 5.8...   \n",
       "278  [48.78592, 11.064767, 8.407269, 7.039444, 6.65...   \n",
       "281  [37.673447, 11.727802, 8.1880665, 7.1784163, 6...   \n",
       "284  [46.5625, 39.316772, 17.49003, 10.495918, 9.45...   \n",
       "287  [48.359787, 27.109566, 15.680702, 13.933253, 1...   \n",
       "\n",
       "                                          Weight Decay  \\\n",
       "0    [1340.811, 1340.6844, 1340.561, 1340.4401, 134...   \n",
       "4    [3341.833, 3341.9233, 3342.1328, 3342.459, 334...   \n",
       "6    [6009.557, 6009.319, 6009.3955, 6009.7773, 601...   \n",
       "9    [9342.156, 9341.23, 9340.908, 9341.171, 9341.9...   \n",
       "12   [13338.912, 13335.697, 13333.5625, 13332.438, ...   \n",
       "..                                                 ...   \n",
       "275  [9526.033, 9935.584, 9980.475, 10001.476, 1001...   \n",
       "278  [13612.924, 13812.055, 13849.014, 13880.938, 1...   \n",
       "281  [18368.146, 18397.58, 18442.668, 18463.33, 184...   \n",
       "284  [23546.506, 23585.86, 23694.807, 23670.02, 236...   \n",
       "287  [29459.785, 29487.56, 29514.674, 29537.557, 29...   \n",
       "\n",
       "                                                 Model  Test MSE  \\\n",
       "0    [Linear(in_features=20, out_features=1000, bia...  0.119706   \n",
       "4    [Linear(in_features=20, out_features=1000, bia...  0.012496   \n",
       "6    [Linear(in_features=20, out_features=1000, bia...  0.000995   \n",
       "9    [Linear(in_features=20, out_features=1000, bia...  0.000695   \n",
       "12   [Linear(in_features=20, out_features=1000, bia...  0.000725   \n",
       "..                                                 ...       ...   \n",
       "275  [Linear(in_features=20, out_features=1000, bia...  0.000092   \n",
       "278  [Linear(in_features=20, out_features=1000, bia...  0.000092   \n",
       "281  [Linear(in_features=20, out_features=1000, bia...  0.000098   \n",
       "284  [Linear(in_features=20, out_features=1000, bia...  0.000095   \n",
       "287  [Linear(in_features=20, out_features=1000, bia...  0.000100   \n",
       "\n",
       "         Activations  Final Train MSE  Final Weight Decay  \n",
       "0    linear and relu         0.000004          228.721588  \n",
       "4    linear and relu         0.000001          178.268677  \n",
       "6    linear and relu         0.000058          147.673447  \n",
       "9    linear and relu         0.000077          151.917374  \n",
       "12   linear and relu         0.000082          166.722778  \n",
       "..               ...              ...                 ...  \n",
       "275  linear and relu         0.000011          597.575500  \n",
       "278  linear and relu         0.000008          581.571960  \n",
       "281  linear and relu         0.000011          625.433533  \n",
       "284  linear and relu         0.000014          720.301086  \n",
       "287  linear and relu         0.000010          819.545837  \n",
       "\n",
       "[96 rows x 12 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = [row[\"lambda\"] == bestlambda[row[\"r\"]][row[\"n\"]][row[\"L\"]][row[\"Activations\"]] for rowindex,row in res.iterrows()]\n",
    "res = res[mask]\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "FLGDlcKf3AOl",
   "metadata": {
    "id": "FLGDlcKf3AOl"
   },
   "source": [
    "# Generalization MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UVGouHlX4iuu",
   "metadata": {
    "id": "UVGouHlX4iuu"
   },
   "source": [
    "## generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3sJ2nZvq4Mpx",
   "metadata": {
    "id": "3sJ2nZvq4Mpx"
   },
   "outputs": [],
   "source": [
    "def gen_data(datasetsize,r,seed,trainsize=2**18,testsize=2**10,d=20,funcseed=42,verbose=False,ood=False,std=0):\n",
    "    ##Generate data with a true central subspaces of varying dimensions\n",
    "    #generate X values for training and test sets\n",
    "    np.random.seed(seed) #set seed for data generation\n",
    "    trainX = np.random.rand(d,trainsize).astype(np.float32)[:,:datasetsize] - 0.5 #distributed as U[-1/2, 1/2]\n",
    "    testX = np.random.rand(d,testsize).astype(np.float32) - 0.5 #distributed as U[-1/2, 1/2]\n",
    "    #out of distribution datagen\n",
    "    if ood:\n",
    "        trainX *= 2 #now distributed as U[-1, 1]\n",
    "        testX *= 2 #now distributed as U[-1, 1]\n",
    "    ##for each $r$ value create and store data-gen functions and $y$ evaluations\n",
    "    #geneate params for functions\n",
    "    k = d+1\n",
    "    U = np.load(job_name+f\"/r{r}U.npy\")\n",
    "    Sigma = np.load(job_name+f\"/r{r}Sigma.npy\")\n",
    "    V = np.load(job_name+f\"/r{r}V.npy\")\n",
    "    A = np.load(job_name+f\"/r{r}A.npy\")\n",
    "    B = np.load(job_name+f\"/r{r}B.npy\")\n",
    "    #create functions\n",
    "    def g(z): #active subspace function\n",
    "        hidden_layer = (U*Sigma)@z\n",
    "        hidden_layer = hidden_layer.T + B\n",
    "        hidden_layer = np.maximum(0,hidden_layer).T\n",
    "        return A@hidden_layer\n",
    "    def f(x): #teacher network\n",
    "        z = V.T@x\n",
    "        eps = torch.normal(mean=torch.zeros(num_pnts),std=std*torch.ones(num_pnts)).to(device)\n",
    "        return g(z) + eps\n",
    "    #generate data\n",
    "    trainY = f(trainX).astype(np.float32)\n",
    "    testY = f(testX).astype(np.float32)\n",
    "    #move data to device\n",
    "    if verbose:\n",
    "        print(\"device: {}\".format(device))\n",
    "    trainX = torch.from_numpy(trainX).T.to(device)\n",
    "    trainY = torch.from_numpy(trainY).to(device)\n",
    "    testX = torch.from_numpy(testX).T.to(device)\n",
    "    testY = torch.from_numpy(testY).to(device)\n",
    "    if verbose:\n",
    "        print(\"trainX shape = {} trainY shape = {}\".format(\n",
    "            trainX.shape,\n",
    "            trainY.shape\n",
    "        ))\n",
    "    return trainX,trainY,testX,testY\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "pNH8hcsX35vb",
   "metadata": {
    "id": "pNH8hcsX35vb"
   },
   "outputs": [],
   "source": [
    "generalizationX,generalizationYr1 = gen_data(2048,r=1,seed=101)[:2]\n",
    "generalizationX,generalizationYr2 = gen_data(2048,r=2,seed=101)[:2]\n",
    "generalizationY = {1:generalizationYr1,2:generalizationYr2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "46d17ac6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2048]) tensor([0., 0., 0.,  ..., 0., 0., 0.], device='cuda:0')\n",
      "torch.Size([2048]) tensor([ 1.5574,  7.7949, 19.1428,  ...,  8.1604, 10.2077,  3.3550],\n",
      "       device='cuda:0', grad_fn=<AddBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7ffa4985f970>]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#evaluate gradients\n",
    "r = 2\n",
    "std = 0\n",
    "U = torch.from_numpy(np.load(job_name+f\"/r{r}U.npy\").astype(np.float32)).to(device)\n",
    "Sigma =  torch.from_numpy(np.load(job_name+f\"/r{r}Sigma.npy\").astype(np.float32)).to(device)\n",
    "V =  torch.from_numpy(np.load(job_name+f\"/r{r}V.npy\").astype(np.float32)).to(device)\n",
    "A =  torch.from_numpy(np.load(job_name+f\"/r{r}A.npy\").astype(np.float32)).to(device)\n",
    "B =  torch.from_numpy(np.load(job_name+f\"/r{r}B.npy\").astype(np.float32)).to(device)\n",
    "def g(z): #active subspace function\n",
    "    hidden_layer = (U*Sigma)@z\n",
    "    hidden_layer = hidden_layer.T + B\n",
    "    hidden_layer = torch.maximum(torch.zeros_like(hidden_layer),hidden_layer).T\n",
    "    return A@hidden_layer\n",
    "def f(x): #teacher network\n",
    "    z = V.T@x\n",
    "    num_pnts = x.shape[1]\n",
    "    eps = torch.normal(mean=torch.zeros(num_pnts),std=std*torch.ones(num_pnts)).to(device)\n",
    "    print(eps.shape,eps)\n",
    "    print((g(z) + eps).shape,g(z) + eps)\n",
    "    return g(z) + eps\n",
    "generalizationX.requires_grad = True\n",
    "predY = f(generalizationX.T)\n",
    "grad = torch.autograd.grad(predY, generalizationX,\n",
    "                        grad_outputs=torch.ones_like(predY),\n",
    "                        create_graph=True)[0].detach().cpu().numpy()\n",
    "#compute active subspace and singular values\n",
    "Uhat,Shat,VhatT = np.linalg.svd(grad)\n",
    "plt.semilogy(Shat,\".-\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1776e88f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf\"{row['r']},{row['n']},{row['L']}\",row[\"Gradient Singular Values\"]/np.sqrt(2048),whichrow,whichcol)\n",
    "ax[whichrow,whichcol].semilogy(row[\"Gradient Singular Values\"]/np.sqrt(2048),label=rf\"$L={row['L']}$\",linewidth=1,alpha=0.7,marker=\".\")\n",
    "ax[whichrow,whichcol].set_xticks(list(range(3,20,4)),list(range(4,21,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "SGjV4q985lrM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1691614314236,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 300
    },
    "id": "SGjV4q985lrM",
    "outputId": "20b86ce8-f70f-4eec-d2cc-4c6313a4bfa0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-0.4999), tensor(0.5000))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generalizationX.min(),generalizationX.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iHCTTCWw4l4s",
   "metadata": {
    "id": "iHCTTCWw4l4s"
   },
   "source": [
    "## compute MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ulWXCTcd2_Xo",
   "metadata": {
    "id": "ulWXCTcd2_Xo"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    generalization = []\n",
    "    for rownum, row in res.iterrows():\n",
    "        predY = row[\"Model\"](generalizationX)\n",
    "        err = nn.functional.mse_loss(predY[:,0],generalizationY[row[\"r\"]]).item()\n",
    "        generalization.append(err)\n",
    "    res[\"Generalization MSE\"] = generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "E29dCTeo8JMH",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 168,
     "status": "ok",
     "timestamp": 1691614317198,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 300
    },
    "id": "E29dCTeo8JMH",
    "outputId": "68f53844-b638-4e9b-9119-df3bd2e1bc9d"
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LbkhZQcT8Z4S",
   "metadata": {
    "id": "LbkhZQcT8Z4S"
   },
   "source": [
    "# Out of Distribution MSE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "GEplm-eG8g74",
   "metadata": {
    "id": "GEplm-eG8g74"
   },
   "source": [
    "## generate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CEql6HYT8cUp",
   "metadata": {
    "id": "CEql6HYT8cUp"
   },
   "outputs": [],
   "source": [
    "oodX,oodYr1 = gen_data(2048,r=1,seed=101,ood=True)[:2] #generate out of distribution data\n",
    "oodX,oodYr2 = gen_data(2048,r=2,seed=101,ood=True)[:2]\n",
    "oodY = {1:oodYr1,2:oodYr2}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "SiXhFaOE8n4j",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 162,
     "status": "ok",
     "timestamp": 1691614317198,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 300
    },
    "id": "SiXhFaOE8n4j",
    "outputId": "cf4681fa-710e-4e13-b705-78939987d20c"
   },
   "outputs": [],
   "source": [
    "oodX.min(),oodX.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "yt15AMGL84jk",
   "metadata": {
    "id": "yt15AMGL84jk"
   },
   "source": [
    "## compute MSE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bkBdsUTD86MO",
   "metadata": {
    "id": "bkBdsUTD86MO"
   },
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    ood_errs = []\n",
    "    for rownum, row in res.iterrows():\n",
    "        predY = row[\"Model\"](oodX)\n",
    "        err = nn.functional.mse_loss(predY[:,0],oodY[row[\"r\"]]).item()\n",
    "        ood_errs.append(err)\n",
    "    res[\"Out of Distribution MSE\"] = ood_errs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mvMXQX0N2rdu",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1691614317567,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 300
    },
    "id": "mvMXQX0N2rdu",
    "outputId": "42fe95e3-2f67-4099-db54-f626625cecb1"
   },
   "outputs": [],
   "source": [
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec05e2a",
   "metadata": {
    "id": "8ec05e2a"
   },
   "source": [
    "# Active Subspace"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pFRGq1re-Uzi",
   "metadata": {
    "id": "pFRGq1re-Uzi"
   },
   "source": [
    "## evaluate gradients and compute singular values and active subspaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4lgLuEqq3jns",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 147,
     "status": "ok",
     "timestamp": 1691614317567,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 300
    },
    "id": "4lgLuEqq3jns",
    "outputId": "7cf4be05-167d-4fea-ea02-8141ac06d635"
   },
   "outputs": [],
   "source": [
    "generalizationY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0jES0e-cYG",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4768,
     "status": "ok",
     "timestamp": 1691614322192,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 300
    },
    "id": "9f0jES0e-cYG",
    "outputId": "5d4441ca-c283-47e7-8957-aaff36383b6a",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grads = []\n",
    "sv = []\n",
    "active_subspace = []\n",
    "subspace_dist = []\n",
    "\n",
    "for rownum, row in res.iterrows():\n",
    "    #compute ground truth active subspace\n",
    "    funcseed = 42\n",
    "    d = 20\n",
    "    k = d+1\n",
    "    U = np.load(job_name+f\"/r{row['r']}U.npy\")\n",
    "    Sigma = np.load(job_name+f\"/r{row['r']}Sigma.npy\")\n",
    "    V = np.load(job_name+f\"/r{row['r']}V.npy\")\n",
    "    W = np.load(job_name+f\"/r{row['r']}W.npy\")\n",
    "    A = np.load(job_name+f\"/r{row['r']}A.npy\")\n",
    "    B = np.load(job_name+f\"/r{row['r']}B.npy\")\n",
    "\n",
    "    #evaluate gradients\n",
    "    generalizationX.requires_grad = True\n",
    "    predY = row[\"Model\"](generalizationX)\n",
    "    grad = torch.autograd.grad(predY, generalizationX,\n",
    "                            grad_outputs=torch.ones_like(predY),\n",
    "                            create_graph=True)[0].detach().cpu().numpy()\n",
    "    grads.append(grad)\n",
    "    #compute active subspace and singular values\n",
    "    Uhat,Shat,VhatT = np.linalg.svd(grad)\n",
    "    Vhat = VhatT.T[:,:row[\"r\"]] #form the basis for the active subspace\n",
    "    active_subspace.append(Vhat)\n",
    "    sv.append(Shat)\n",
    "\n",
    "    subspace_dist.append(np.linalg.norm(V@V.T - Vhat@Vhat.T,2))\n",
    "\n",
    "res[\"Gradient Evaluations\"] = grads\n",
    "res[\"Gradient Singular Values\"] = sv\n",
    "res[\"Active Subspace\"] = active_subspace\n",
    "res[\"Active Subspace Distance\"] = subspace_dist\n",
    "res[\"Active Subspace Alignment Angle (Degrees)\"] = np.degrees(np.arcsin(res[\"Active Subspace Distance\"]))\n",
    "\n",
    "res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "LgNlou47LI5H",
   "metadata": {
    "id": "LgNlou47LI5H"
   },
   "source": [
    "## plot of singular values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HQzSc0LhQHYo",
   "metadata": {
    "id": "HQzSc0LhQHYo"
   },
   "outputs": [],
   "source": [
    "# colors = {(1,64):\"tab:blue\",(1,2048):\"tab:cyan\",(2,64):\"tab:orange\",(2,128):\"tab:pink\",(2,256):\"tab:red\",(2,2048):\"tab:purple\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d98a90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.n.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bMbfBUBiLIIm",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 3264,
     "status": "ok",
     "timestamp": 1691614325292,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 300
    },
    "id": "bMbfBUBiLIIm",
    "outputId": "ad4e65df-2f79-43e6-c268-0137c510ccb6",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=len(res.r.unique()), ncols=len(res.n.unique()), sharex=True, sharey=True, figsize=(10,4.8))#len(res.r.unique()),len(res.n.unique())\n",
    "for rownum,row in res.iterrows():\n",
    "    whichrow = np.where(row['r'] == res.r.unique())[0][0]\n",
    "    whichcol = np.where(row['n'] == res.n.unique())[0][0]\n",
    "    print(whichrow,whichcol)\n",
    "    #whichax = row['L'] - 2\n",
    "#     color = colors[(row['L'])]\n",
    "    print(rf\"{row['r']},{row['n']},{row['L']}\",row[\"Gradient Singular Values\"]/np.sqrt(2048),whichrow,whichcol)\n",
    "    ax[whichrow,whichcol].semilogy(row[\"Gradient Singular Values\"]/np.sqrt(2048),label=rf\"$L={row['L']}$\",linewidth=1,alpha=0.7,marker=\".\")\n",
    "    ax[whichrow,whichcol].set_xticks(list(range(3,20,4)),list(range(4,21,4)))\n",
    "    ax[whichrow,whichcol].set_ylim(10**-9,10**3)\n",
    "    ax[0,whichcol].set_title(rf\"$n={row['n']}$\")\n",
    "    ax[-1,whichcol].set_xlabel(rf\"Index, $k$\")\n",
    "plt.subplot(2,len(res.n.unique()),1)\n",
    "leg = plt.legend()\n",
    "leg = plt.legend(bbox_to_anchor=(-1, 1))\n",
    "leg.get_frame().set_edgecolor('b')\n",
    "leg.get_frame().set_linewidth(0.0)\n",
    "plt.subplot(2,len(res.n.unique()),1)\n",
    "plt.ylabel(r\"$r=1$\"+\"\\n\"+r\"$\\sigma_k(\\hat f;\\rho)$\")\n",
    "plt.yticks([10**p for p in range(-8,3,2)])\n",
    "plt.subplot(2,len(res.n.unique()),len(res.n.unique())+1)\n",
    "plt.ylabel(r\"$r=2$\"+\"\\n\"+r\"$\\sigma_k(\\hat f;\\rho)$\")\n",
    "plt.yticks([10**p for p in range(-8,3,2)])\n",
    "plt.suptitle(\"Singular Values of Trained Networks\")\n",
    "plt.tight_layout()\n",
    "plt.savefig(job_name+\"/sv.png\",dpi=300,bbox_extra_artists=(leg,), bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fabcf44",
   "metadata": {
    "id": "QfTgwsYWt0JN"
   },
   "source": [
    "#  determine the L parameter that gets the best test MSE for each (r,n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0fc2546",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 645
    },
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1701128292779,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 360
    },
    "id": "RJvhVj2QsOzz",
    "outputId": "f5ab0e61-f93e-4d47-c809-af5ef4d06e06",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "testmse_vs_L = res.pivot_table(values=\"Test MSE\",index = (\"r\",\"n\",\"Activations\"),columns=[\"L\"])\n",
    "testmse_vs_L = testmse_vs_L.iloc[:,1:]\n",
    "testmse_vs_L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8500da45",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1701128292779,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 360
    },
    "id": "VAo89WtwHFHa",
    "outputId": "8e14cccf-c936-4617-ee75-266196fa044a"
   },
   "outputs": [],
   "source": [
    "bestL = testmse_vs_L.idxmin(axis=1)\n",
    "bestL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66eb5ccf",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 960
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1701128292779,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 360
    },
    "id": "K4ItJEBcjtcZ",
    "outputId": "a6ab9ade-ea9d-4b83-b14b-29dd2811b57d"
   },
   "outputs": [],
   "source": [
    "mask = [row[\"L\"] == bestL[row[\"r\"]][row[\"n\"]][row[\"Activations\"]] for rowindex,row in res.iterrows()]\n",
    "bestLres = res[mask]\n",
    "bestLres"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vKIELwC_GeZK",
   "metadata": {
    "id": "vKIELwC_GeZK"
   },
   "source": [
    "# Plots of L vs Test error and n vs Generalization metrics with/without linear layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650453b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.r.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gvOUGojKGWvw",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "executionInfo": {
     "elapsed": 1932,
     "status": "ok",
     "timestamp": 1701129174191,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 360
    },
    "id": "gvOUGojKGWvw",
    "outputId": "378581a5-d4b5-4eed-8e60-29b5134124ff",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(ncols=len(res.r.unique()),nrows=1, sharex=True, sharey=True, figsize=(10,4.8))\n",
    "for rnum,r in enumerate(res.r.unique()):\n",
    "    for n in res.n.unique():\n",
    "        res_rn = res[(res.r == r) * (res.n == n)]\n",
    "        ax[rnum].scatter(res_rn.L,res_rn[[\"Test MSE\"]])\n",
    "        ax[rnum].semilogy(res_rn.L,res_rn[[\"Test MSE\"]],label=rf\"$n={n}$\")\n",
    "    ax[rnum].set_xlabel(\"$L$ number of layers\")\n",
    "    ax[rnum].set_title(rf\"$r={r}$\")\n",
    "ax[0].legend()\n",
    "ax[0].set_ylabel(\"Validation MSE\")\n",
    "f.suptitle(rf\"Validation MSE for best $\\lambda$ values\")\n",
    "f.tight_layout()\n",
    "f.savefig(job_name+f\"/Validation MSE.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f53158aa",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for metric in ['Generalization MSE', 'Out of Distribution MSE','Active Subspace Alignment Angle (Degrees)']:\n",
    "    f, ax = plt.subplots(ncols=len(res.r.unique()),nrows=1, sharex=True, sharey=True, figsize=(10,4.8))\n",
    "    for rnum,r in enumerate(res.r.unique()):\n",
    "        plt.subplot(1,2,r)\n",
    "        #best L\n",
    "        curr = bestLres[bestLres.r == r]\n",
    "        ax[rnum].scatter(curr.n,curr[[metric]])\n",
    "        ax[rnum].plot(curr.n,curr[[metric]],label=rf\"linear layers\")\n",
    "        #no linear layers\n",
    "        no_lin_layers = res[(res.r == r) * (res.L == 2)]\n",
    "        ax[rnum].scatter(no_lin_layers.n,no_lin_layers[[metric]])\n",
    "        ax[rnum].plot(no_lin_layers.n,no_lin_layers[[metric]],label=rf\"no linear layers\")\n",
    "        #plotting extras\n",
    "        ax[rnum].set_xlabel(\"$n$ number of samples\")\n",
    "        ax[rnum].set_xscale(\"log\",base=2)\n",
    "        if metric != 'Active Subspace Alignment Angle (Degrees)':\n",
    "            ax[rnum].set_yscale(\"log\",base=10)\n",
    "        ax[rnum].set_title(rf\"$r={r}$\")\n",
    "    ax[0].set_ylabel(f\"{metric}\")\n",
    "    ax[0].legend()\n",
    "    plt.suptitle(f\"{metric}\" + r\" with best $(\\lambda,L)$ tuning\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(job_name+f\"/{metric}.png\",dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MSXEnXHGw7io",
   "metadata": {
    "id": "MSXEnXHGw7io"
   },
   "source": [
    "# Final Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d8c8ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "res.loc[(res.L == 2),\"Activations\"] = \"Shallow ReLU\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc983977",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestLres = pd.concat((res[(res.L == 2)],bestLres))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9df0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "bestLres.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1TzfteO6vNt8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 709
    },
    "executionInfo": {
     "elapsed": 450,
     "status": "ok",
     "timestamp": 1691614327155,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 300
    },
    "id": "1TzfteO6vNt8",
    "outputId": "1b069b14-373c-4b2f-9008-de82e499721e",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pivot_table = bestLres.pivot_table(index=(\"r\",\"n\",\"Activations\"))\n",
    "print(pivot_table.shape)\n",
    "pivot_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "lsgPlcM2ZuL8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 437,
     "status": "ok",
     "timestamp": 1691614327156,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 300
    },
    "id": "lsgPlcM2ZuL8",
    "outputId": "e3acd77a-de4a-4577-ad35-7f6986b334e2"
   },
   "outputs": [],
   "source": [
    "pivot_table.idxmin(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "GkLJGWl6Jhvb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 185
    },
    "executionInfo": {
     "elapsed": 596,
     "status": "ok",
     "timestamp": 1691614327320,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 300
    },
    "id": "GkLJGWl6Jhvb",
    "outputId": "ec6695a5-ba3b-438b-ece9-6ef83eb55c57"
   },
   "outputs": [],
   "source": [
    "pivot_table_latex = pivot_table.drop([\"Final Weight Decay\"],axis=1)\n",
    "pivot_table_latex = pivot_table_latex[[\"L\",\"lambda\",\"Final Train MSE\",\"Generalization MSE\",\"Out of Distribution MSE\",\"Active Subspace Alignment Angle (Degrees)\"]]\n",
    "pivot_table_latex.to_latex(float_format=\"%.2e\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ifHWhLg6ZLTN",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 640
    },
    "executionInfo": {
     "elapsed": 149,
     "status": "ok",
     "timestamp": 1691614327321,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 300
    },
    "id": "ifHWhLg6ZLTN",
    "outputId": "c6d90379-87de-4056-d5ec-bdf7221078ad",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pivot_table_latex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5107327",
   "metadata": {
    "id": "b5107327"
   },
   "source": [
    "# Training Time Plots"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Hp2Lu9--zMIb",
   "metadata": {
    "id": "Hp2Lu9--zMIb"
   },
   "source": [
    "## Train MSE v Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8wl7kIk6zeFC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 8615,
     "status": "ok",
     "timestamp": 1691614335789,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 300
    },
    "id": "8wl7kIk6zeFC",
    "outputId": "7e484e6e-2b87-4d05-c230-e7ff9715720f",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=len(res.r.unique()), ncols=len(res.n.unique()), sharex=True, sharey=True, figsize=(20,10))#len(res.r.unique()),len(res.n.unique())\n",
    "plt.figure(figsize=(10,10))\n",
    "for rownum,row in res.iterrows():\n",
    "    if row[\"L\"] <= 4:\n",
    "        whichrow = np.where(row['r'] == res.r.unique())[0][0]\n",
    "        whichcol = np.where(row['n'] == res.n.unique())[0][0]\n",
    "        ax[whichrow,whichcol].semilogy(row[\"Train MSE\"],label=rf\"$L = {row['L']}$\",linewidth=1,alpha=0.5)\n",
    "        ax[whichrow,whichcol].set_title(rf\"$r = {row['r']},n = {row['n']}$\")\n",
    "        ax[whichrow,whichcol].set_xlabel(\"Epoch\")\n",
    "ax[0,0].legend()\n",
    "f.suptitle(\"Train MSE v Epoch\")\n",
    "f.savefig(job_name+\"/trainmse234.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f6e277",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=len(res.r.unique()), ncols=len(res.n.unique()), sharex=True, sharey=True, figsize=(20,10))#len(res.r.unique()),len(res.n.unique())\n",
    "plt.figure(figsize=(10,10))\n",
    "for rownum,row in res.iterrows():\n",
    "    if 4 < row[\"L\"] <= 7:\n",
    "        whichrow = np.where(row['r'] == res.r.unique())[0][0]\n",
    "        whichcol = np.where(row['n'] == res.n.unique())[0][0]\n",
    "        ax[whichrow,whichcol].semilogy(row[\"Train MSE\"],label=rf\"$L = {row['L']}$\",linewidth=1,alpha=0.5)\n",
    "        ax[whichrow,whichcol].set_title(rf\"$r = {row['r']},n = {row['n']}$\")\n",
    "        ax[whichrow,whichcol].set_xlabel(\"Epoch\")\n",
    "ax[0,0].legend()\n",
    "f.suptitle(\"Train MSE v Epoch\")\n",
    "f.savefig(job_name+\"/trainmse567.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e819cc9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=len(res.r.unique()), ncols=len(res.n.unique()), sharex=True, sharey=True, figsize=(20,10))\n",
    "plt.figure(figsize=(10,10))\n",
    "for rownum,row in res.iterrows():\n",
    "    if row[\"L\"] > 7:\n",
    "        whichrow = np.where(row['r'] == res.r.unique())[0][0]\n",
    "        whichcol = np.where(row['n'] == res.n.unique())[0][0]\n",
    "        ax[whichrow,whichcol].semilogy(row[\"Train MSE\"],label=rf\"$L = {row['L']}$\",linewidth=1,alpha=0.5)\n",
    "        ax[whichrow,whichcol].set_title(rf\"$r = {row['r']},n = {row['n']}$\")\n",
    "        ax[whichrow,whichcol].set_xlabel(\"Epoch\")\n",
    "ax[0,0].legend()\n",
    "f.suptitle(\"Train MSE v Epoch\")\n",
    "f.savefig(job_name+\"/trainmse8910.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hvvaxGFp1Y4b",
   "metadata": {
    "id": "hvvaxGFp1Y4b"
   },
   "source": [
    "## Weight Decay v Epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "BqaDyKjy1GFF",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 5930,
     "status": "ok",
     "timestamp": 1691614341548,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 300
    },
    "id": "BqaDyKjy1GFF",
    "outputId": "19920698-1700-4629-b33b-664e5fc59f89"
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(len(res.r.unique()), ncols=len(res.n.unique()), sharex=True, sharey=True, figsize=(20,10))#len(res.r.unique()),len(res.n.unique())\n",
    "plt.figure(figsize=(10,10))\n",
    "for rownum,row in res.iterrows():\n",
    "    whichrow = np.where(row['r'] == res.r.unique())[0][0]\n",
    "    whichcol = np.where(row['n'] == res.n.unique())[0][0]\n",
    "    ax[whichrow,whichcol].semilogy(row[\"Weight Decay\"],label=rf\"$L = {row['L']}$\",linewidth=1,alpha=0.7)\n",
    "    ax[whichrow,whichcol].set_title(rf\"$r = {row['r']},n = {row['n']}$\")\n",
    "    ax[whichrow,whichcol].set_xlabel(\"Epoch\")\n",
    "ax[0,0].legend()\n",
    "f.suptitle(\"Weight Decay v Epoch\")\n",
    "f.savefig(job_name+\"/weightdecay.png\",dpi=300)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wq6OpgxBzJ0b",
   "metadata": {
    "id": "wq6OpgxBzJ0b"
   },
   "source": [
    "## learning rates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8532c1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 989
    },
    "executionInfo": {
     "elapsed": 1246,
     "status": "ok",
     "timestamp": 1691614342623,
     "user": {
      "displayName": "Suzanna Parkinson",
      "userId": "17585917766009932288"
     },
     "user_tz": 300
    },
    "id": "af8532c1",
    "outputId": "ca06e30a-a8a6-4050-b984-529474874d5d",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "f, ax = plt.subplots(nrows=len(res.r.unique()), ncols=len(res.n.unique()), sharex=True, sharey=True, figsize=(20,10))#len(res.r.unique()),len(res.n.unique())\n",
    "plt.figure(figsize=(10,10))\n",
    "for rownum,row in res.iterrows():\n",
    "    whichrow = np.where(row['r'] == res.r.unique())[0][0]\n",
    "    whichcol = np.where(row['n'] == res.n.unique())[0][0]\n",
    "    ax[whichrow,whichcol].semilogy(row[\"Learning Rate\"],label=rf\"$L = {row['L']}$\",linewidth=1,alpha=0.7)\n",
    "    ax[whichrow,whichcol].set_title(rf\"$r = {row['r']},n = {row['n']}$\")\n",
    "    ax[whichrow,whichcol].set_xlabel(\"Epoch\")\n",
    "ax[0,0].legend()\n",
    "f.suptitle(\"Learning Rate v Epoch\")\n",
    "f.savefig(job_name+\"/LearningRate.png\",dpi=300)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "165px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
